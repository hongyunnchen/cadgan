{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook to test kernel herding (solving the kernel moment matching sequentially) with a GAN generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#%config InlineBackend.figure_format = 'svg'\n",
    "#%config InlineBackend.figure_format = 'pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cadgan\n",
    "import cadgan.kernel as kernel\n",
    "import cadgan.glo as glo\n",
    "import cadgan.main as main\n",
    "import cadgan.plot as plot\n",
    "import cadgan.embed as embed\n",
    "import cadgan.util as util\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# font options\n",
    "font = {\n",
    "    #'family' : 'normal',\n",
    "    #'weight' : 'bold',\n",
    "    'size'   : 18\n",
    "}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "plt.rc('lines', linewidth=2)\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = True and torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "torch.set_default_tensor_type(torch.cuda.FloatTensor if use_cuda else torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extractor for MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "import cadgan.mnist.classify as mnist_classify\n",
    "from cadgan.mnist.classify import MnistClassifier\n",
    "\n",
    "\n",
    "classifier = mnist_classify.MnistClassifier(load=True)\n",
    "classifier = classifier.eval()\n",
    "classifier = classifier.to(device)\n",
    "# classifier = classifier.cuda()\n",
    "\n",
    "def extractor(imgs):\n",
    "    \"\"\"\n",
    "    Feature extractor\n",
    "    \"\"\"\n",
    "#     return classifier.features(imgs)\n",
    "    self = classifier\n",
    "    x = imgs\n",
    "    x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "    x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "\n",
    "#     x = x.view(-1, 10*12*12)\n",
    "    x = x.view(-1, 320)\n",
    "#     x = x.view(-1)\n",
    "#     x = F.relu(self.fc1(x))\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load MNIST data\n",
    "mnist_folder = glo.data_file('mnist')\n",
    "mnist_dataset = torchvision.datasets.MNIST(mnist_folder, download=True,train=False, \n",
    "                        transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ]))\n",
    "print(mnist_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xy = mnist_dataset[92]\n",
    "x = xy[0]\n",
    "x = x.unsqueeze(0)\n",
    "x = x.to(device)\n",
    "\n",
    "# plot\n",
    "xnp = np.transpose(xy[0].numpy(), (1, 2, 0))\n",
    "xnp = xnp.squeeze()\n",
    "plt.imshow(xnp)\n",
    "print('features: ', classifier(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A generator for MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cadgan.mnist.dcgan as mnist_dcgan\n",
    "import cadgan.mnist.util as mnist_util\n",
    "\n",
    "# load a model\n",
    "g = mnist_dcgan.Generator(load=True)\n",
    "\n",
    "latent_dim = 100\n",
    "f_noise = lambda n: torch.randn(n, latent_dim).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize points jointly to minimize the moment matching loss\n",
    "\n",
    "With a GAN generator. Optimize in the latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# label_counts = [(1, 3), (9, 3)]\n",
    "# label_counts = [(6, 2), (8, 2)]\n",
    "label_counts = [(6, 4)]\n",
    "# label_counts = [(1,1), (2,1), (3,1), (4,1)]\n",
    "# label_counts = [(i, 5) for i in range(10)]\n",
    "# label_counts = [(0, 6), (5, 3)]\n",
    "X = mnist_util.pt_sample_by_labels(mnist_dataset, label_counts)\n",
    "X = X.to(device)\n",
    "n = X.shape[0]\n",
    "\n",
    "# A vector of weights for all the points in X\n",
    "weights = torch.ones(n)/float(n)\n",
    "weights = weights.to(device)\n",
    "plot.show_torch_imgs(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel on the extracted features\n",
    "# k = kernel.PTKGauss(sigma2=50.0)\n",
    "# k = kernel.PTKPoly(c=1e-1, d=2)\n",
    "# k = kernel.PTKIMQ(c=1e+1, b=-0.5)\n",
    "# k = kernel.PTKIMQ()\n",
    "k = kernel.PTKLinear()\n",
    "\n",
    "# kernel on the latent noise vectors\n",
    "# k = kernel.PTKFuncCompose(kgauss, classifier)\n",
    "\n",
    "# pre-extract the features of X. Fixed throughout the optimization\n",
    "with torch.no_grad():\n",
    "    FX = extractor(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# initial points in the latent space\n",
    "# n_sample = 2*2**3\n",
    "# n_sample = 2*8\n",
    "n_sample = 6\n",
    "# noise vectors\n",
    "Z = f_noise(n_sample)\n",
    "Z = Z.to(device)\n",
    "\n",
    "Z.requires_grad = True\n",
    "Y0 = g(Z)\n",
    "\n",
    "# plot the initial points in the image space\n",
    "plot.show_torch_imgs(Y0.detach(), nrow=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kernel herding (sequentially solving the kernel moment matching problem) with a generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def kernel_generator_herding(X, weights, g, extractor, \n",
    "#                              k, Z0, fn_make_optimizer=None, n_iter=200, ):\n",
    "\"\"\"\n",
    "X: Pytorch tensor containing samples in the target mean embedding\n",
    "weights: Pytorch vector containing weights for the samples in X\n",
    "g: an instance of cadgan.gen.PTNoiseTransformer representing a generator\n",
    "extractor: a feature extractor\n",
    "k: a kernel. An instance of PTKernel. This is used on top of the outputs from the extractor.\n",
    "Z0: Pytorch tensor containing initial noise vectors to be optimized further.\n",
    "    Z0[i, :] is point i. Each point is used in order.\n",
    "fn_make_optimizer: a function: params -> a torch.optim.XXX optimizer. \n",
    "    A function that constructs an optimizer from a list of parameters.\n",
    "n_iter: number of iterations for optimizing each y_i \n",
    "\n",
    "Return (Y, Y0), \n",
    "    Y: a Pytorch tensor of size n_sample x dim. Optimization result\n",
    "    Y0: a Pytorch tensor of size n_sample x dim. Initial points picked\n",
    "\"\"\"\n",
    "Z0 = Z\n",
    "n_iter = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if n_sample <= 0:\n",
    "    raise ValueError('n_sample must be > 0. Was {}'.format(n_sample))\n",
    "# if fn_make_optimizer is None:\n",
    "fn_make_optimizer = lambda params: torch.optim.Adam(params, lr=5e-2)\n",
    "\n",
    "g = g.eval()\n",
    "n = X.shape[0]\n",
    "# a stack of all initial points\n",
    "Y0 = []\n",
    "# first iteration. Initialize.\n",
    "z1 = Z0[[0]].detach().clone()\n",
    "z1.requires_grad = True\n",
    "y1 = g(z1)\n",
    "Y0.append(y1.detach().clone())\n",
    "\n",
    "# pre-extract features of X\n",
    "with torch.no_grad():\n",
    "    FX = extractor(X)\n",
    "\n",
    "Losses = np.zeros((n_sample, n_iter))\n",
    "# mean_KFX = torch.mean(k.eval(FX, FX))\n",
    "\n",
    "# optimization for the first point\n",
    "optimizer1 = fn_make_optimizer([z1])\n",
    "reg = 1e-3\n",
    "for it in range(n_iter):\n",
    "    y1 = g(z1)\n",
    "    fea1 = extractor(y1)\n",
    "    z1_reg = reg*torch.sum(z1**2)\n",
    "    loss1 = -2.0*k.eval(fea1, FX).mv(weights) + k.eval(fea1, fea1).reshape(-1) + z1_reg\n",
    "    \n",
    "    Losses[0, it] = loss1.item()\n",
    "    # optimize z1\n",
    "    optimizer1.zero_grad()\n",
    "\n",
    "    # compute the gradients\n",
    "    loss1.backward(retain_graph=True)\n",
    "    # updates\n",
    "    optimizer1.step()\n",
    "\n",
    "# tensor to store the optimized points\n",
    "Y = torch.cat([y1], dim=0)\n",
    "# extracted features of points until iteration t-1\n",
    "FY = torch.cat([fea1], dim=0)\n",
    "\n",
    "# optimized Z\n",
    "Z = torch.cat([z1], dim=0)\n",
    "for t in range(2, n_sample+1):\n",
    "    zt = Z0[[t-1]].detach().clone()\n",
    "    zt.requires_grad = True\n",
    "    yt = g(zt)\n",
    "    Y0.append(yt.clone())\n",
    "\n",
    "    optimizert = fn_make_optimizer([zt])  \n",
    "    # optimization loop\n",
    "    for it in range(n_iter):\n",
    "        yt = g(zt)\n",
    "        feat = extractor(yt)\n",
    "        zt_reg = reg*torch.sum(zt**2)\n",
    "        # optimize the rest of y2, ...y_{n_sample}\n",
    "        losst =  - (2.0/t)*k.eval(feat, FX).mv(weights) \\\n",
    "            + (2.0/t**2)*torch.sum(k.eval(FY, feat)) + (1.0/t**2)*k.eval(feat, feat).reshape(-1) \\\n",
    "            + zt_reg\n",
    "\n",
    "        Losses[t-1, it] = losst.item()\n",
    "#             print(losst.item())\n",
    "        # optimize zt\n",
    "        optimizert.zero_grad()\n",
    "        losst.backward(retain_graph=True)\n",
    "        optimizert.step()\n",
    "\n",
    "    # Now we have yt. Add it to the current set Y\n",
    "    Y = torch.cat([Y, yt], dim=0)\n",
    "    FY = torch.cat([FY, feat], dim=0)\n",
    "    Z = torch.cat([Z, zt], dim=0)\n",
    "\n",
    "assert Y.shape[0] == n_sample\n",
    "assert FY.shape[0] == n_sample\n",
    "Y0 = torch.cat(Y0, 0)\n",
    "#     return Y, Y0\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(Losses.T)\n",
    "plt.xlabel('Optimization iteration')\n",
    "plt.ylabel('Herding loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input points\n",
    "plot.show_torch_imgs(X)\n",
    "plt.title('Input')\n",
    "\n",
    "plot.show_torch_imgs(Y0.detach(), nrow=8)\n",
    "plt.title('Initialized')\n",
    "\n",
    "gen = Y.detach().cpu()\n",
    "plot.show_torch_imgs(gen)\n",
    "plt.title('Output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(Z.cpu().detach().numpy())\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
