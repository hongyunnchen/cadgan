{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook to test kernel herding with a GAN generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#%config InlineBackend.figure_format = 'svg'\n",
    "#%config InlineBackend.figure_format = 'pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kbrgan\n",
    "import kbrgan.kernel as kernel\n",
    "import kbrgan.glo as glo\n",
    "import kbrgan.main as main\n",
    "import kbrgan.plot as plot\n",
    "import kbrgan.embed as embed\n",
    "import kbrgan.util as util\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# font options\n",
    "font = {\n",
    "    #'family' : 'normal',\n",
    "    #'weight' : 'bold',\n",
    "    'size'   : 18\n",
    "}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "plt.rc('lines', linewidth=2)\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = True and torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "torch.set_default_tensor_type(torch.cuda.FloatTensor if use_cuda else torch.FloatTensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extractor for MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = torchvision.models.resnet18(pretrained=True)\n",
    "classifier = classifier.eval()\n",
    "classifier = classifier.to(device)\n",
    "def extractor(imgs):\n",
    "    \"\"\"\n",
    "    Feature extractor\n",
    "    \"\"\"\n",
    "    self = classifier\n",
    "    x=imgs   \n",
    "#     up = nn.Upsample(size=224, mode='bilinear')\n",
    "    up = nn.Upsample(size=96, mode='bilinear')\n",
    "    x = up(x)\n",
    "    x = self.conv1(x)\n",
    "    x = self.bn1(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.maxpool(x)\n",
    "#     print(x.shape)\n",
    "    return x.view(-1, 64*24*24)\n",
    "#     return x.view(-1, 64*16*16)\n",
    "#     print(x.shape)\n",
    "#     return x.view(-1, 64*112*112)\n",
    "#     return x.view(-1, 64*56*56)\n",
    "#     x = self.layer1(x)\n",
    "#     x = self.layer2(x)\n",
    "#     x = x.view(-1, 100352 )\n",
    "#     return x\n",
    "#     return x.view(-1, 64*56*56)\n",
    "    \n",
    "#x = self.layer3(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A generator for MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class Generator(nn.Module):\n",
    "    '''\n",
    "        Generative Network\n",
    "    '''\n",
    "    def __init__(self, dataset='celebA'):\n",
    "        \n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        z_size=100\n",
    "        out_size=3\n",
    "        ngf=128\n",
    "        \n",
    "        self.z_size = z_size\n",
    "        self.ngf = ngf\n",
    "        self.out_size = out_size\n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            # input size is z_size\n",
    "            nn.ConvTranspose2d(self.z_size, self.ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(self.ngf * 8),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # state size: (ngf * 8) x 4 x 4\n",
    "            nn.ConvTranspose2d(self.ngf * 8, self.ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(self.ngf * 4),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # state size: (ngf * 4) x 8 x 8\n",
    "            nn.ConvTranspose2d(self.ngf * 4, self.ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(self.ngf * 2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # state size: (ngf * 2) x 16 x 16\n",
    "            nn.ConvTranspose2d(self.ngf * 2, self.ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(self.ngf),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # state size: ngf x 32 x 32\n",
    "            nn.ConvTranspose2d(self.ngf, self.out_size, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size: out_size x 64 x 64\n",
    "        )\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.ConvTranspose2d):\n",
    "                m.weight.data.normal_(0.0, 0.02)\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "\n",
    "    def forward(self, input):\n",
    "\n",
    "        output = self.main(input)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def load(self,f):\n",
    "        \"\"\"\n",
    "        Load a Generator from a file. To be used with save().\n",
    "        \"\"\"\n",
    "        self.load_state_dict(torch.load((f)))\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kbrgan.mnist.dcgan as mnist_dcgan\n",
    "\n",
    "gan_fname = 'GAN_{}_G.pkl'.format(24)\n",
    "gan_fpath = glo.prob_model_folder('lsun_dcgan', gan_fname)\n",
    "\n",
    "# load a model\n",
    "g = Generator()\n",
    "g.load(gan_fpath)\n",
    "\n",
    "latent_dim = 100\n",
    "f_noise = lambda n: torch.randn(n, latent_dim).float()\n",
    "\n",
    "#sample_z_ = Variable(torch.rand((batch_size, z_dim)).view(-1, z_dim, 1, 1), requires_grad=False).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize points jointly to minimize the moment matching loss\n",
    "\n",
    "With a GAN generator. Optimize in the latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_from_dir(dir_data, num_sample):\n",
    "    list_selected = []\n",
    "    #labels = np.array([data[i][1] for i in range(len(data))])\n",
    "    for item in range(num_sample):\n",
    "        list_selected.extend(homo_data)\n",
    "    # stack all\n",
    "    selected = torch.stack(list_selected)\n",
    "    return selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "num_input = 1\n",
    "test_img_dir = glo.data_file('test_bedroom')\n",
    "imgs = []\n",
    "for path in np.random.permutation(os.listdir(test_img_dir))[0:num_input]:\n",
    "    img = Image.open(os.path.join(test_img_dir,path))\n",
    "\n",
    "    img = img.resize((64,64))\n",
    "    img = np.transpose(np.array(img),(2,0,1))\n",
    "    imgs.append(img/255.0)\n",
    "    \n",
    "#img = np.transpose(np.array(img),(2,0,1)).reshape((1,3,64,64))\n",
    "X = torch.tensor(imgs).float()\n",
    "X = X.to(device)\n",
    "n = X.shape[0]\n",
    "\n",
    "# A vector of weights for all the points in X\n",
    "weights = torch.ones(n)/float(n)\n",
    "weights = weights.to(device)\n",
    "plot.show_torch_imgs(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# initial points in the latent space\n",
    "# n_sample = 2*2**3\n",
    "n_sample = 8\n",
    "# noise vectors\n",
    "Z = f_noise(n_sample).view(-1, latent_dim, 1, 1)\n",
    "Z = Z.to(device)\n",
    "\n",
    "Z.requires_grad = True\n",
    "Y0 = g(Z)\n",
    "\n",
    "# plot the initial points in the image space\n",
    "plot.show_torch_imgs(Y0.detach(), nrow=8, figsize=(12,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = torch.optim.SGD([Y], lr=5e-3)\n",
    "optimizer = torch.optim.RMSprop([Z], lr=2e-2)\n",
    "# optimizer = torch.optim.Adam([Z], lr=1e-2)\n",
    "# kernel on the extracted features\n",
    "\n",
    "# k = kernel.PTKPoly(c=1e-1, d=2)\n",
    "# k = kernel.PTKIMQ()\n",
    "# k = kernel.PTKIMQ(c=1e+0, b=-0.5)\n",
    "# k = kernel.PTKLaplace(sigma=1)\n",
    "# k = kernel.PTKLinear()\n",
    "k = kernel.PTKL1Distance(sigma=2e+3)\n",
    "\n",
    "# kernel on the latent noise vectors\n",
    "# k = kernel.PTKFuncCompose(kgauss, classifier)\n",
    "\n",
    "# pre-extract the features of X. Fixed throughout the optimization\n",
    "\n",
    "with torch.no_grad():\n",
    "    FX = extractor(X)\n",
    "\n",
    "# med = util.meddistance(FX.detach().cpu().numpy(), subsample=1000)\n",
    "# k = kernel.PTKGauss(sigma2=med**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# optimization\n",
    "n_iter = 1200\n",
    "losses = []\n",
    "sample_interval = 300\n",
    "# avgpool = torch.nn.AvgPool2d(5, stride=1, padding=0)\n",
    "\n",
    "mean_KFX = torch.mean(k.eval(FX, FX))\n",
    "for t in range(n_iter):\n",
    "    # need to resize since Mnist uses 28x28. The generator generates 32x32\n",
    "    gens = g(Z)\n",
    "#     resized = torch.stack([resize_gen_img(I) for I in gens], 0)\n",
    "#     resized = avgpool(gens)\n",
    "#     plot.show_torch_imgs(resized)\n",
    "    F_gz = extractor(gens)\n",
    "    KF_gz = k.eval(F_gz, F_gz)\n",
    "#     print(KF_gz)\n",
    "    \n",
    "    # encourage the latent noise vectors to concentrate around 0\n",
    "    Z_reg = 1e-2*torch.mean(torch.mean(Z**2, 1))\n",
    "#     Z_reg = -torch.mean(torch.log(4.0**2-Z**2))\n",
    "    loss = torch.mean(KF_gz)  - 2.0*torch.mean(k.eval(F_gz, FX).mv(weights)) + mean_KFX  + Z_reg\n",
    "    losses.append(loss.item())\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # compute the gradients\n",
    "    loss.backward(retain_graph=True)\n",
    "    # updates\n",
    "    optimizer.step()\n",
    "    \n",
    "    #--------- plots the generated images ----\n",
    "    if t%sample_interval==0:\n",
    "        with torch.no_grad():\n",
    "            gen = g(Z.detach().clone())\n",
    "#             gen = Z.detach().clone()\n",
    "#             gen = Z.grad.detach().clone()\n",
    "            plot.show_torch_imgs(gen, figsize=(12, 6))\n",
    "            plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# input points\n",
    "figsize = (12, 6)\n",
    "plot.show_torch_imgs(X)\n",
    "plt.title('Input')\n",
    "plot.show_torch_imgs(Y0.detach(), nrow=8, figsize=figsize)\n",
    "plt.title('Initialized')\n",
    "plot.show_torch_imgs(gen, figsize=figsize)\n",
    "plt.title('Output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)\n",
    "plt.xlabel('Optimization iteration')\n",
    "plt.ylabel('Herding loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(Z.detach().cpu().squeeze().numpy())\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
