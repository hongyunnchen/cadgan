{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#%config InlineBackend.figure_format = 'svg'\n",
    "#%config InlineBackend.figure_format = 'pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kbrgan\n",
    "import kbrgan.kernel as kernel\n",
    "import kbrgan.main as main\n",
    "import kbrgan.embed as embed\n",
    "import kbrgan.util as util\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import autograd.numpy as np\n",
    "import scipy.stats as stats\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# font options\n",
    "font = {\n",
    "    #'family' : 'normal',\n",
    "    #'weight' : 'bold',\n",
    "    'size'   : 18\n",
    "}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "plt.rc('lines', linewidth=2)\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel embedding in 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 2\n",
    "n = 500\n",
    "seed = 7\n",
    "torch.manual_seed(seed);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = torch.randn(n, d)\n",
    "Xnp = X.numpy()\n",
    "plt.plot(Xnp[:, 0], Xnp[:, 1], 'ko');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "med = util.meddistance(X.numpy(), subsample=1000)\n",
    "print('median distance: ', med)\n",
    "# Gaussian kernel\n",
    "k = kernel.PTKGauss(sigma2=med**2/2)\n",
    "# create a mean embedding\n",
    "em = embed.PTImplicitKEmb(k, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize points jointly to minimize the moment matching loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Sample from a mean embedding by performing kernel moment matching.\n",
    "\"\"\";\n",
    "n_sample = 30\n",
    "\n",
    "# Y = stack of output samples to be optimized.\n",
    "# Initialize by picking a subset from X\n",
    "Y = torch.tensor(X[np.random.choice(n, n_sample)] + torch.randn(n_sample, 1)*0.1, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ynp = Y.detach().numpy()\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(Xnp[:, 0], Xnp[:, 1], 'ko', label='Data', alpha=0.4);\n",
    "plt.plot(Ynp[:, 0], Ynp[:, 1], '^b', markersize=11, alpha=0.7, label='Initialized')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = torch.optim.Adam([Y], lr=1e-3)\n",
    "# optimizer = torch.optim.SGD([Y], lr=5e-3)\n",
    "optimizer = torch.optim.RMSprop([Y], lr=1e-3)\n",
    "# optimization\n",
    "n_iter = 1000\n",
    "losses = []\n",
    "for t in range(n_iter):\n",
    "    loss = ( torch.mean(k.eval(Y, Y)) - 2.0*torch.mean(k.eval(Y, X).mv(em.weights)) )\n",
    "    losses.append(loss.item())\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # compute the gradients\n",
    "    loss.backward()\n",
    "    # updates\n",
    "    optimizer.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(np.arange(n_iter)+1, losses, 'b-')\n",
    "plt.ylabel('Moment matching loss')\n",
    "plt.xlabel('Iteration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ynp = Y.detach().numpy()\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(Xnp[:, 0], Xnp[:, 1], 'ko', label='Data', alpha=0.4);\n",
    "plt.plot(Ynp[:, 0], Ynp[:, 1], '^b', markersize=11, alpha=0.7, label='Optimized')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel herding (greedy optimization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_herding(emb, n_sample, fn_make_optimizer=None, n_iter=200, ):\n",
    "    \"\"\"\n",
    "    emb: PTImplicitKEmb to sample from\n",
    "    n_sample: number of points to sample\n",
    "    fn_make_optimizer: a function: params -> a torch.optim.XXX optimizer. \n",
    "        A function that constructs an optimizer from a list of parameters.\n",
    "    n_iter: number of iterations for optimizing each y_i \n",
    "    \n",
    "    Return (Y, Y0), \n",
    "        Y: a Pytorch tensor of size n_sample x dim. Optimization result\n",
    "        Y0: a Pytorch tensor of size n_sample x dim. Initial points picked\n",
    "    \"\"\"\n",
    "    if n_sample <= 0:\n",
    "        raise ValueError('n_sample must be > 0. Was {}'.format(n_sample))\n",
    "    if fn_make_optimizer is None:\n",
    "        fn_make_optimizer = lambda params: torch.optim.RMSprop(params, lr=1e-3)\n",
    "        \n",
    "    def pick_one_row(X):\n",
    "        n = X.shape[0]\n",
    "        return torch.tensor(X[np.random.choice(n,1)] + torch.randn(1)*0.1, requires_grad=True)\n",
    "    X = emb.samples\n",
    "    n = X.shape[0]\n",
    "    k = emb.get_kernel()\n",
    "    \n",
    "    # a stack of all initial points\n",
    "    Y0 = []\n",
    "    # first iteration. Initialize by randomly picking a point in X.\n",
    "    y1 = pick_one_row(X)\n",
    "    Y0.append(y1.clone())\n",
    "#     y1 = y1.unsqueeze(0)\n",
    "    assert y1.ndimension() == 2, 'dim of y1 was {}'.format(y1.ndimension())\n",
    "    \n",
    "    optimizer1 = fn_make_optimizer([y1])\n",
    "    for it in range(n_iter):\n",
    "        loss1 = 2.0*emb.eval(y1).reshape(-1) - k.eval(y1, y1).reshape(-1)\n",
    "        # optimize y1\n",
    "        optimizer1.zero_grad()\n",
    "\n",
    "        # compute the gradients\n",
    "        loss1.backward()\n",
    "        # updates\n",
    "        optimizer1.step()\n",
    "        \n",
    "    Y = torch.cat([y1], dim=0)\n",
    "    for t in range(2, n_sample+1):\n",
    "        yt = pick_one_row(X)\n",
    "        Y0.append(yt.clone())\n",
    "        # add a dimension on axis=0\n",
    "#         yt = yt.unsqueeze(0)\n",
    "        \n",
    "        optimizert = fn_make_optimizer([yt])\n",
    "        \n",
    "        # optimization loop\n",
    "        for it in range(n_iter):\n",
    "            # optimize the rest of y2, ...y_{n_sample}\n",
    "            losst = 2.0*torch.sum(emb.eval(Y)) \\\n",
    "                - (2.0/t)*torch.sum(k.eval(Y, yt)) - (1.0/t)*k.eval(yt, yt).reshape(-1)\n",
    "#             print(losst.item())\n",
    "            # optimize yt\n",
    "            optimizert.zero_grad()\n",
    "            losst.backward()\n",
    "            optimizert.step()\n",
    "        \n",
    "        # Now we have yt. Add it to the current set Y\n",
    "        Y = torch.cat([Y, yt], dim=0)\n",
    "        \n",
    "    assert Y.shape[0] == n_sample\n",
    "    Y0 = torch.cat(Y0, 0)\n",
    "    return Y, Y0\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sample = 20\n",
    "# number of optimization iterations for each point yt\n",
    "n_iter = 300\n",
    "\n",
    "def fn_make_optimizer(params):\n",
    "#     return torch.optim.RMSprop(params, lr=1e-3)\n",
    "    return torch.optim.Adam(params, lr=1e-3)\n",
    "#     return torch.optim.SGD(params, lr=1e-3)\n",
    "Y_greedy, Y0 = kernel_herding(em, n_sample, fn_make_optimizer, n_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ynp = Y_greedy.detach().numpy()\n",
    "Y0np = Y0.detach().numpy()\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(Xnp[:, 0], Xnp[:, 1], 'ko', label='Data', alpha=0.4);\n",
    "plt.plot(Y0np[:, 0], Y0np[:, 1], 'sb', markersize=11, alpha=0.7, label='Initial')\n",
    "plt.plot(Ynp[:, 0], Ynp[:, 1], '^r', markersize=11, alpha=0.7, label='Optimized')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
