{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A notebook to test the idea of distributional autoencoders i.e., autoencoders which take as input a distribution and map it to a representation in ways that preserve the information in the distribution. In practice, a distribution can be represented by a finite collection of points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#%config InlineBackend.figure_format = 'svg'\n",
    "#%config InlineBackend.figure_format = 'pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kbrgan\n",
    "import kbrgan.kernel as kernel\n",
    "import kbrgan.glo as glo\n",
    "import kbrgan.main as main\n",
    "import kbrgan.plot as plot\n",
    "import kbrgan.embed as embed\n",
    "import kbrgan.net as net\n",
    "import kbrgan.util as util\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# font options\n",
    "font = {\n",
    "    #'family' : 'normal',\n",
    "    #'weight' : 'bold',\n",
    "    'size'   : 18\n",
    "}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "plt.rc('lines', linewidth=2)\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = True and torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "tensor_type = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "# torch.set_default_tensor_type(tensor_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR10 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kbrgan.cifar10.util as cifar10_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "trdata_folder = glo.data_file('cifar10')\n",
    "trdata = torchvision.datasets.CIFAR10(trdata_folder, train=True, download=True,\n",
    "                        transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "#                            transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pixel intensity range\n",
    "stats.describe(trdata[2][0].numpy().reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see the data\n",
    "ntr = trdata.train_data.shape[0]\n",
    "img_size = trdata.train_data.shape[1:]\n",
    "\n",
    "# randomly select a few images\n",
    "k = 3*8\n",
    "inds = np.random.choice(ntr, size=k, replace=False)\n",
    "xs = [trdata[i][0] for i in inds] \n",
    "# classes\n",
    "ys = [trdata[i][1] for i in inds] \n",
    "\n",
    "# x = x.to(device)\n",
    "print('{} randomly chosen images:'.format(k))\n",
    "plot.show_torch_imgs(xs, figsize=(10, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('CIFAR10 classes and their indices:')\n",
    "cifar10_class_inds = cifar10_util.label_class_list()\n",
    "display(cifar10_class_inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick only some classes for simplicity\n",
    "# classes = [1, 9]\n",
    "classes = [1]\n",
    "# classes = list(range(10))\n",
    "# numpy arrays\n",
    "X = trdata.train_data\n",
    "Y = np.array(trdata.train_labels)\n",
    "\n",
    "# filter data according to the chosen classes\n",
    "tr_inds = [Y[i] in classes for i in range(len(Y)) ]\n",
    "Xtr = X[tr_inds]\n",
    "Ytr = Y[tr_inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the range to be from min to max\n",
    "minmax = (0.0, 1.0)\n",
    "0c\n",
    "Tr = torch.utils.data.TensorDataset(torch.tensor(Xtr.transpose(0, 3, 1, 2), device='cpu', dtype=torch.float), \n",
    "                                    torch.tensor(Ytr, device='cpu', dtype=torch.float))\n",
    "\n",
    "batch_size = 2**8\n",
    "train_loader = torch.utils.data.DataLoader(Tr, batch_size=batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see the data of the selected classes\n",
    "\n",
    "# randomly select a few images\n",
    "k = 4*8\n",
    "nTr = Tr.tensors[0].shape[0]\n",
    "inds = np.random.choice(nTr, size=k, replace=False)\n",
    "xs = [Tr[i][0] for i in inds] \n",
    "# classes\n",
    "ys = [Tr[i][1] for i in inds] \n",
    "\n",
    "# x = x.to(device)\n",
    "print('{} randomly chosen images:'.format(k))\n",
    "plot.show_torch_imgs(xs, figsize=(12, 6), normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pixel intensity range\n",
    "stats.describe(Tr[8][0].numpy().reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser(description='Train a DCGAN on CIFAR10')\n",
    "parser.add_argument('--n_epochs', type=int, default=200, help='number of epochs of training')\n",
    "parser.add_argument('--batch_size', type=int, default=64, help='size of the batches')\n",
    "parser.add_argument('--lr', type=float, default=0.0002, help='adam: learning rate')\n",
    "parser.add_argument('--b1', type=float, default=0.5, help='adam: decay of first order momentum of gradient')\n",
    "parser.add_argument('--b2', type=float, default=0.999, help='adam: decay of first order momentum of gradient')\n",
    "parser.add_argument('--latent_dim', type=int, default=100, help='dimensionality of the latent space')\n",
    "parser.add_argument('--sample_interval', type=int, default=400, help='interval between image sampling')\n",
    "parser.add_argument('--prob_model_dir', type=str, help='interval between image sampling')\n",
    "parser.add_argument('--classes', type=int, help='a list of integers (0-9) denoting the classes to consider', nargs='+')\n",
    "\n",
    "args = parser.parse_args(['--n_epochs', '2'])\n",
    "vars(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''.join(map(str, [2,3,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted([3,2,6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a distributional autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Extractor1(net.SerializableModule):\n",
    "    def __init__(self, channels=3, minmax=(0.0, 1.0)):\n",
    "        super(Extractor1, self).__init__()\n",
    "        self.minmax = minmax\n",
    "        def conv_leaky_max(in_filters, out_filters, bn=True):\n",
    "            block = [   nn.Conv2d(in_filters, out_filters, kernel_size=3, stride=2, padding=1),\n",
    "                        nn.LeakyReLU(0.2, inplace=True),\n",
    "                      ]\n",
    "            if bn:\n",
    "                block.append(nn.BatchNorm2d(out_filters, 0.8))\n",
    "            return block\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *conv_leaky_max(channels, 16, bn=False), # input = 32x32\n",
    "            *conv_leaky_max(16, 32), # \n",
    "            *conv_leaky_max(32, 64), # \n",
    "            *conv_leaky_max(64, 96), # output 2x2\n",
    "            nn.MaxPool2d(kernel_size=2, stride=1, padding=0),\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        # normalize image value range to be in [-1, 1]\n",
    "        minmax = self.minmax\n",
    "        mi, ma = minmax[0], minmax[1]\n",
    "        img = (img - mi)/float(ma - mi)*2.0 - 1\n",
    "        out = self.model(img)\n",
    "        out = out.view(out.shape[0], -1)\n",
    "        # print(out.shape)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hyperparameters for the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of epochs\n",
    "n_epochs = 80\n",
    "\n",
    "# a function to return the number of points to draw to construct\n",
    "# an empirical distribution. Points are drawn from a minibatch.\n",
    "# The range of this function should be positive integers.\n",
    "func_subbatch_size = lambda n: 1+stats.poisson.rvs(mu=5, size=n)\n",
    "\n",
    "# create a network\n",
    "network = Extractor1(channels=3, minmax=(0.0, 1.0))\n",
    "network = network.to(device)\n",
    "\n",
    "# output dimension of the network\n",
    "output_dim = network(Tr[[0]][0].to(device)).shape[1]\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.Adam(network.parameters(), lr=1e-2)\n",
    "\n",
    "# number of times to sample empirical distributions per minibatch\n",
    "n_sample_per_minibatch = 10\n",
    "\n",
    "# regularization parameter\n",
    "reg = 1e-2\n",
    "\n",
    "print('output dimension: ', output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Iden = torch.eye(output_dim, dtype=torch.float, device=device)\n",
    "list_losses = []\n",
    "# training\n",
    "for epoch in range(n_epochs):\n",
    "    for batch_idx, (batch, _) in enumerate(train_loader):\n",
    "        BX = batch.to(device)\n",
    "        subbatch_sizes = func_subbatch_size(n_sample_per_minibatch)\n",
    "        # minibatch mean embedding\n",
    "        BY = network(BX)\n",
    "        batch_embed = torch.mean(BY, dim=0)\n",
    "        # orthogonality constraint\n",
    "        ortho_penalty = torch.sum((BY.t().mm(BY) - Iden)**2)   \n",
    "        \n",
    "        minibatch_loss = 0\n",
    "        for si in range(n_sample_per_minibatch):\n",
    "            subbatch_inds = np.random.choice(BX.shape[0], subbatch_sizes[si], replace=False)\n",
    "            subBX = BX[subbatch_inds]     \n",
    "\n",
    "            # loss: averaged MMD on subbatch embedding\n",
    "            sub_embed = torch.mean(network(subBX), dim=0)\n",
    "            # subbatch mean embedding\n",
    "            sub_loss = torch.sum((batch_embed - sub_embed)**2) \n",
    "            minibatch_loss += sub_loss/float(n_sample_per_minibatch)\n",
    "            \n",
    "        minibatch_loss += reg*ortho_penalty\n",
    "        optimizer.zero_grad()\n",
    "        minibatch_loss.backward()\n",
    "        # update the parameters\n",
    "        optimizer.step()        \n",
    "        list_losses.append(minibatch_loss.item())\n",
    "#                 print(sub_embed[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds = list(range(len(list_losses)))[50:]\n",
    "losses = np.array(list_losses)\n",
    "plt.plot(inds, losses[inds], label='tr-loss')\n",
    "plt.xlabel('#minibatch update')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ortho_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
