{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A notebook to test the idea of distributional autoencoders i.e., autoencoders which take as input a distribution and map it to a representation in ways that preserve the information in the distribution. In practice, a distribution can be represented by a finite collection of points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#%config InlineBackend.figure_format = 'svg'\n",
    "#%config InlineBackend.figure_format = 'pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cadgan\n",
    "import cadgan.kernel as kernel\n",
    "import cadgan.glo as glo\n",
    "import cadgan.main as main\n",
    "import cadgan.plot as plot\n",
    "import cadgan.embed as embed\n",
    "import cadgan.net.net as net\n",
    "import cadgan.util as util\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# font options\n",
    "font = {\n",
    "    #'family' : 'normal',\n",
    "    #'weight' : 'bold',\n",
    "    'size'   : 18\n",
    "}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "plt.rc('lines', linewidth=2)\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = True and torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "tensor_type = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "# torch.set_default_tensor_type(tensor_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR10 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cadgan.cifar10.util as cifar10_util\n",
    "print('CIFAR10 classes and their indices:')\n",
    "cifar10_class_inds = cifar10_util.label_class_list()\n",
    "display(cifar10_class_inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes = [0,]\n",
    "classes = list(range(10))\n",
    "# classes = [8]\n",
    "Tr = cifar10_util.load_cifar10_class_subsets(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see the data of the selected classes\n",
    "\n",
    "# randomly select a few images\n",
    "k = 3*8\n",
    "nTr = Tr.tensors[0].shape[0]\n",
    "inds = np.random.choice(nTr, size=k, replace=False)\n",
    "xs = [Tr[i][0] for i in inds] \n",
    "# classes\n",
    "ys = [Tr[i][1] for i in inds] \n",
    "\n",
    "# x = x.to(device)\n",
    "print('{} randomly chosen images:'.format(k))\n",
    "plot.show_torch_imgs(xs, figsize=(12, 6), normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pixel intensity range\n",
    "print(stats.describe(Tr[8][0].numpy().reshape(-1)))\n",
    "\n",
    "batch_size = 2**8\n",
    "train_loader = torch.utils.data.DataLoader(Tr, batch_size=batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a distributional autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Extractor1(net.SerializableModule):\n",
    "    def __init__(self, channels=3, minmax=(0.0, 1.0)):\n",
    "        super(Extractor1, self).__init__()\n",
    "        self.minmax = minmax\n",
    "        def conv_leaky_max(in_filters, out_filters, bn=True):\n",
    "            block = [   nn.Conv2d(in_filters, out_filters, kernel_size=3, stride=2, padding=1),\n",
    "                        nn.LeakyReLU(0.2, inplace=True),\n",
    "                      ]\n",
    "            if bn:\n",
    "                block.append(nn.BatchNorm2d(out_filters, 0.8))\n",
    "            return block\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *conv_leaky_max(channels, 16, bn=False), # input = 32x32\n",
    "            *conv_leaky_max(16, 32), # \n",
    "            *conv_leaky_max(32, 64), # \n",
    "            *conv_leaky_max(64, 96), # output 2x2\n",
    "            nn.MaxPool2d(kernel_size=2, stride=1, padding=0),\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        # normalize image value range to be in [-1, 1]\n",
    "        minmax = self.minmax\n",
    "        mi, ma = minmax[0], minmax[1]\n",
    "        img = (img - mi)/float(ma - mi)*2.0 - 1\n",
    "        out = self.model(img)\n",
    "        out = out.view(out.shape[0], -1)\n",
    "        # print(out.shape)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hyperparameters for the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of epochs\n",
    "n_epochs = 80\n",
    "\n",
    "# a function to return the number of points to draw to construct\n",
    "# an empirical distribution. Points are drawn from a minibatch.\n",
    "# The range of this function should be positive integers.\n",
    "func_subbatch_size = lambda n: 1+stats.poisson.rvs(mu=5, size=n)\n",
    "\n",
    "# create a network\n",
    "network = Extractor1(channels=3, minmax=(0.0, 1.0))\n",
    "network = network.to(device)\n",
    "\n",
    "# output dimension of the network\n",
    "output_dim = network(Tr[[0]][0].to(device)).shape[1]\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.Adam(network.parameters(), lr=1e-2)\n",
    "\n",
    "# number of times to sample empirical distributions per minibatch\n",
    "n_sample_per_minibatch = 10\n",
    "\n",
    "# regularization parameter\n",
    "reg = 1e-2\n",
    "\n",
    "print('output dimension: ', output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Iden = torch.eye(output_dim, dtype=torch.float, device=device)\n",
    "list_losses = []\n",
    "# training\n",
    "for epoch in range(n_epochs):\n",
    "    for batch_idx, (batch, _) in enumerate(train_loader):\n",
    "        print('\\repoch: '+str(epoch+1)+'/'+str(n_epochs) + '\\titr: '+str(batch_idx+1)+'/'+str(len(train_loader)),end=\"\")\n",
    "        BX = batch.to(device)\n",
    "        subbatch_sizes = func_subbatch_size(n_sample_per_minibatch)\n",
    "        # minibatch mean embedding\n",
    "        BY = network(BX)\n",
    "        batch_embed = torch.mean(BY, dim=0)\n",
    "        # orthogonality constraint\n",
    "        ortho_penalty = torch.sum((BY.t().mm(BY) - Iden)**2)   \n",
    "        \n",
    "        minibatch_loss = 0\n",
    "        for si in range(n_sample_per_minibatch):\n",
    "            subbatch_inds = np.random.choice(BX.shape[0], subbatch_sizes[si], replace=False)\n",
    "            subBX = BX[subbatch_inds]     \n",
    "\n",
    "            # loss: averaged MMD on subbatch embedding\n",
    "            sub_embed = torch.mean(network(subBX), dim=0)\n",
    "            # subbatch mean embedding\n",
    "            sub_loss = torch.sum((batch_embed - sub_embed)**2) \n",
    "            minibatch_loss += sub_loss/float(n_sample_per_minibatch)\n",
    "            \n",
    "        minibatch_loss += reg*ortho_penalty\n",
    "        optimizer.zero_grad()\n",
    "        minibatch_loss.backward()\n",
    "        # update the parameters\n",
    "        optimizer.step()        \n",
    "        list_losses.append(minibatch_loss.item())\n",
    "#                 print(sub_embed[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds = list(range(len(list_losses)))[50:]\n",
    "losses = np.array(list_losses)\n",
    "plt.plot(inds, losses[inds], label='tr-loss')\n",
    "plt.xlabel('#minibatch update')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ortho_penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the trained encoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = sorted(classes)\n",
    "cls_str = ''.join(map(str, classes))\n",
    "prob_model_dir_name = 'cifar10_c{}-distenc'.format(cls_str)\n",
    "prob_model_dir = glo.prob_model_folder(prob_model_dir_name)\n",
    "os.makedirs(prob_model_dir, exist_ok=True)\n",
    "\n",
    "model_fname = '{}-ep{}_bs{}.pt'.format(prob_model_dir_name,  n_epochs, batch_size)\n",
    "model_fpath = os.path.join(prob_model_dir, model_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the encoder\n",
    "network.save(model_fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
