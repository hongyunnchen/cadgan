{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook to test kernel moment matching with a GAN generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#%config InlineBackend.figure_format = 'svg'\n",
    "#%config InlineBackend.figure_format = 'pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kbrgan\n",
    "import kbrgan.kernel as kernel\n",
    "import kbrgan.glo as glo\n",
    "import kbrgan.main as main\n",
    "import kbrgan.plot as plot\n",
    "import kbrgan.embed as embed\n",
    "import kbrgan.util as util\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# font options\n",
    "font = {\n",
    "    #'family' : 'normal',\n",
    "    #'weight' : 'bold',\n",
    "    'size'   : 18\n",
    "}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "plt.rc('lines', linewidth=2)\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = True and torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "torch.set_default_tensor_type(torch.cuda.FloatTensor if use_cuda else torch.FloatTensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extractor for MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = glo.prob_model_folder('mnist_cnn_ep40_s1.pt')\n",
    "# load the model\n",
    "import kbrgan.mnist.classify as mnist_classify\n",
    "from kbrgan.mnist.classify import MnistClassifier\n",
    "\n",
    "# load option depends on whether GPU is used\n",
    "load_options = {} if use_cuda else {'map_location': lambda storage, loc: storage} \n",
    "\n",
    "classifier = mnist_classify.MnistClassifier.load(model_path, **load_options)\n",
    "classifier = classifier.eval()\n",
    "classifier = classifier.to(device)\n",
    "# classifier = classifier.cuda()\n",
    "\n",
    "def extractor(imgs):\n",
    "    \"\"\"\n",
    "    Feature extractor\n",
    "    \"\"\"\n",
    "#     return classifier.features(imgs)\n",
    "    self = classifier\n",
    "    x = imgs\n",
    "    x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "    x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "\n",
    "#     x = x.view(-1, 10*12*12)\n",
    "    x = x.view(-1, 320)\n",
    "#     x = x.view(-1)\n",
    "#     x = F.relu(self.fc1(x))\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load MNIST data\n",
    "mnist_folder = glo.data_file('mnist')\n",
    "mnist_dataset = torchvision.datasets.MNIST(mnist_folder, train=False, \n",
    "                        transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xy = mnist_dataset[92]\n",
    "x = xy[0]\n",
    "x = x.unsqueeze(0)\n",
    "x = x.to(device)\n",
    "\n",
    "# plot\n",
    "xnp = n\n",
    "p.transpose(xy[0].numpy(), (1, 2, 0))\n",
    "xnp = xnp.squeeze()\n",
    "plt.imshow(xnp)\n",
    "print('features: ', classifier(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A generator for MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kbrgan.mnist.dcgan as mnist_dcgan\n",
    "\n",
    "gan_fname = 'mnist_dcgan_ep{}_bs{}.pt'.format(40, 64)\n",
    "gan_fpath = glo.prob_model_folder('mnist_dcgan', gan_fname)\n",
    "\n",
    "# load a model\n",
    "g = mnist_dcgan.Generator.load(gan_fpath, **load_options)\n",
    "g = g.to(device)\n",
    "\n",
    "latent_dim = 100\n",
    "f_noise = lambda n: torch.randn(n, latent_dim).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize points jointly to minimize the moment matching loss\n",
    "\n",
    "With a GAN generator. Optimize in the latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def resize_gen_img(y):\n",
    "#     # original Mnist images are 28x28 pixels\n",
    "#     # The generator generates 32x32 images.\n",
    "#     # Apply the following rescaling filter: 32x32 -> 28x28.\n",
    "    \n",
    "# #     y = y.clone() # need this clone because Normalize modifies in-place.\n",
    "#     downscale_op = transforms.Compose([\n",
    "#         # undo the range normalization\n",
    "#         # When training the GAN, the following was used: transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "#         transforms.Normalize((0,), (1.0/0.5,)),\n",
    "#         transforms.Normalize((-0.5,), (1,)),\n",
    "#         transforms.ToPILImage(),\n",
    "#         transforms.Resize((28, 28)),\n",
    "#         transforms.ToTensor(),\n",
    "#         # renormalize\n",
    "#         transforms.Normalize((0.1307,), (0.3081,)),\n",
    "#     ])\n",
    "#     return downscale_op(y)\n",
    "\n",
    "# def scale_up_real_img(x):\n",
    "#     \"\"\"\n",
    "#     original Mnist images are 28x28 pixels\n",
    "#     The generator generates 32x32 images.\n",
    "#     Apply the following rescaling filter on real Mnist iamges: 28x28 -> 32x32\n",
    "#     \"\"\"\n",
    "#     downscale_op = transforms.Compose([\n",
    "#         # undo the range normalization\n",
    "#         # When training the GAN, the following was used: transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "#         transforms.Normalize((0,), (1.0/0.3081,)),\n",
    "#         transforms.Normalize((-0.1307,), (1,)),\n",
    "#         transforms.ToPILImage(),\n",
    "#         transforms.Resize((32, 32)),\n",
    "#         transforms.ToTensor(),\n",
    "#         # renormalize\n",
    "#         transforms.Normalize((0.1307,), (0.3081,)),\n",
    "#     ])\n",
    "#     return downscale_op(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = resize_gen_img(Y0[0].clone())\n",
    "# plot.show_torch_imgs(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def sample_by_labels(data, label_counts):\n",
    "    \"\"\"\n",
    "    data: a dataset such that data[i][0] is a point, and data[i][1] is an integer label.\n",
    "    label_counts: a list of tuples of two values (A, B), where A is a label, and B is the count.\n",
    "    \"\"\"\n",
    "    list_selected = []\n",
    "    labels = np.array([data[i][1] for i in range(len(data))])\n",
    "    for label, count in label_counts:\n",
    "        inds = np.where(labels==label)[0]\n",
    "        homo_data = [data[i][0] for i in inds[:count]]\n",
    "        list_selected.extend(homo_data)\n",
    "    # stack all\n",
    "    selected = torch.stack(list_selected)\n",
    "    return selected\n",
    "\n",
    "# The set of points representing the mean embedding that we want to sample from.\n",
    "# As an example, we will construct this manually.\n",
    "# img_indices = [2, 5, 9, 12, 14, 16, 17, 20, 26, 29, 31, 34, 36, 37]\n",
    "# img_indices = [2, 5, 14, 29, 31, 37, 39, 40, 46, 57]\n",
    "# img_indices = [3, 5]\n",
    "# X = torch.stack([mnist_dataset[i][0] for i in img_indices], dim=0)\n",
    "\n",
    "# label_counts = [(1, 5), (9, 5)]\n",
    "# label_counts = [(1, 6), (7, 2)]\n",
    "# label_counts = [(9, 1)]\n",
    "# label_counts = [(4, 5)]\n",
    "label_counts = [(6, 2), (8, 2)]\n",
    "# label_counts = [(1,1), (2,1), (3,1), (4,1)]\n",
    "# label_counts = [(i, 5) for i in range(10)]\n",
    "# label_counts = [(0, 6)]\n",
    "X = sample_by_labels(mnist_dataset, label_counts)\n",
    "X = X.to(device)\n",
    "n = X.shape[0]\n",
    "\n",
    "# A vector of weights for all the points in X\n",
    "weights = torch.ones(n)/float(n)\n",
    "weights = weights.to(device)\n",
    "plot.show_torch_imgs(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# initial points in the latent space\n",
    "# n_sample = 2*2**3\n",
    "# n_sample = 2*8\n",
    "n_sample = 8*2\n",
    "# noise vectors\n",
    "Z = f_noise(n_sample)\n",
    "Z = Z.to(device)\n",
    "\n",
    "Z.requires_grad = True\n",
    "Y0 = g(Z)\n",
    "\n",
    "# plot the initial points in the image space\n",
    "plot.show_torch_imgs(Y0.detach(), nrow=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# pre-extract the features of X. Fixed throughout the optimization\n",
    "with torch.no_grad():\n",
    "    FX = extractor(X)\n",
    "    \n",
    "# optimizer = torch.optim.SGD([Y], lr=5e-3)\n",
    "optimizer = torch.optim.RMSprop([Z], lr=5e-2)\n",
    "# optimizer = torch.optim.Adam([Z], lr=5e-2)\n",
    "\n",
    "# kernel on the extracted features\n",
    "med = util.meddistance(FX.cpu().numpy(), subsample=1000)\n",
    "# k = kernel.PTKGauss(sigma2=med**2)\n",
    "# k = kernel.PTKPoly(c=1e-1, d=2)\n",
    "k = kernel.PTKIMQ(c=1e+2, b=-0.5)\n",
    "# k = kernel.PTKLinear()\n",
    "\n",
    "# kernel on the latent noise vectors\n",
    "# k = kernel.PTKFuncCompose(kgauss, classifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# avgpool = torch.nn.AvgPool2d(5, stride=1, padding=0)\n",
    "# avgpool = avgpool.to(device)\n",
    "# scaled = avgpool(Y0).detach()\n",
    "# plot.show_torch_imgs(scaled)\n",
    "# scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# optimization\n",
    "n_iter = 1000\n",
    "losses = []\n",
    "sample_interval = 200\n",
    "# avgpool = torch.nn.AvgPool2d(5, stride=1, padding=0)\n",
    "\n",
    "mean_KFX = torch.mean(k.eval(FX, FX))\n",
    "for t in range(n_iter):\n",
    "    # need to resize since Mnist uses 28x28. The generator generates 32x32\n",
    "    gens = g(Z)\n",
    "#     resized = torch.stack([resize_gen_img(I) for I in gens], 0)\n",
    "#     resized = avgpool(gens)\n",
    "#     plot.show_torch_imgs(resized)\n",
    "    F_gz = extractor(gens)\n",
    "    KF_gz = k.eval(F_gz, F_gz)\n",
    "#     print(KF_gz)\n",
    "    \n",
    "    # encourage the latent noise vectors to concentrate around 0\n",
    "    Z_reg = 1e-6*torch.mean(torch.sum(Z**2, 1))\n",
    "#     Z_reg = -torch.mean(torch.log(4.0**2-Z**2))\n",
    "    loss = torch.mean(KF_gz)  - 2.0*torch.mean(k.eval(F_gz, FX).mv(weights)) + mean_KFX  + Z_reg\n",
    "    losses.append(loss.item())\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # compute the gradients\n",
    "    loss.backward(retain_graph=True)\n",
    "    # updates\n",
    "    optimizer.step()\n",
    "    \n",
    "    #--------- plots the generated images ----\n",
    "    if t%sample_interval==0:\n",
    "        with torch.no_grad():\n",
    "            gen = g(Z.detach().clone())\n",
    "#             gen = Z.detach().clone()\n",
    "#             gen = Z.grad.detach().clone()\n",
    "            plot.show_torch_imgs(gen)\n",
    "            plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input points\n",
    "plot.show_torch_imgs(X)\n",
    "plt.title('Input')\n",
    "plot.show_torch_imgs(Y0.detach(), nrow=8)\n",
    "plt.title('Initialized')\n",
    "plot.show_torch_imgs(gen)\n",
    "plt.title('Output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)\n",
    "plt.xlabel('Optimization iteration')\n",
    "plt.ylabel('Herding loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(Z.cpu().detach().numpy())\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
