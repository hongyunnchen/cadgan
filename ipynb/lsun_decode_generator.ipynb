{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A notebook to experiment with decoding a generated image from a GAN model. Decoding here refers to the task of finding the noise vector $z$ for a GAN model $g$ such that $g(z)$ (generated image) is closest to a given image.\n",
    "\n",
    "LSUN data. Use models from https://arxiv.org/abs/1801.04406"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#%config InlineBackend.figure_format = 'svg'\n",
    "#%config InlineBackend.figure_format = 'pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kbrgan\n",
    "import kbrgan.kernel as kernel\n",
    "import kbrgan.glo as glo\n",
    "import kbrgan.gen as gen\n",
    "import kbrgan.main as main\n",
    "import kbrgan.plot as plot\n",
    "import kbrgan.net.net as net\n",
    "import kbrgan.util as util\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# font options\n",
    "font = {\n",
    "    #'family' : 'normal',\n",
    "    #'weight' : 'bold',\n",
    "    'size'   : 18\n",
    "}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "plt.rc('lines', linewidth=2)\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True to use GPU\n",
    "use_cuda = True and torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "tensor_type = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "torch.set_default_tensor_type(tensor_type)\n",
    "\n",
    "# load option depends on whether GPU is used\n",
    "load_options = {'map_location': lambda storage, loc: storage.cuda(0)} if use_cuda \\\n",
    "    else {'map_location': lambda storage, loc: storage} \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load an LSUN model from https://arxiv.org/abs/1801.04406"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ganstab\n",
    "import ganstab.configs\n",
    "from ganstab.gan_training.config import (load_config, build_generator, build_models)\n",
    "from ganstab.gan_training.distributions import get_ydist, get_zdist\n",
    "from ganstab.gan_training.checkpoints import CheckpointIO\n",
    "\n",
    "# # generator's type\n",
    "# g_type = 'lsun_bridge.yaml'\n",
    "# # relative generator path\n",
    "# # g_rel_path = 'gan_data/lsun_bridge/chkpts/model.pt'\n",
    "# checkpoint_dir = glo.share_path('gan_data', 'lsun_bridge', 'chkpts')\n",
    "\n",
    "# # generator's type\n",
    "# g_type = 'lsun_church.yaml'\n",
    "# # relative generator path\n",
    "# # g_rel_path = 'gan_data/lsun_bridge/chkpts/model.pt'\n",
    "# checkpoint_dir = glo.share_path('gan_data', 'lsun_church', 'chkpts')\n",
    "\n",
    "# generator's type\n",
    "g_type = 'lsun_bedroom.yaml'\n",
    "# relative generator path\n",
    "# g_rel_path = 'gan_data/lsun_bridge/chkpts/model.pt'\n",
    "checkpoint_dir = glo.share_path('gan_data', 'lsun_bedrooms', 'chkpts')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Configs for LarsGAN\n",
    "yaml_folder = os.path.dirname(ganstab.configs.__file__)\n",
    "yaml_config_path = os.path.join(yaml_folder, g_type)\n",
    "config = load_config(yaml_config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = build_generator(config)\n",
    "# Put models on gpu if needed\n",
    "with torch.enable_grad(): #use_cuda??????\n",
    "    generator = generator.to(device)\n",
    "    \n",
    "# Use multiple GPUs if possible\n",
    "generator = nn.DataParallel(generator)\n",
    "\n",
    "checkpoint_io = CheckpointIO(checkpoint_dir=checkpoint_dir)    \n",
    "# Register modules to checkpoint\n",
    "checkpoint_io.register_modules(generator=generator)\n",
    "\n",
    "# Test generator\n",
    "if config['test']['use_model_average']:\n",
    "    import copy\n",
    "    generator_test = copy.deepcopy(generator)\n",
    "    checkpoint_io.register_modules(generator_test=generator_test)\n",
    "else:\n",
    "    generator_test = generator\n",
    "\n",
    "# Loading Generator\n",
    "# it = checkpoint_io.load(glo.share_path(g_rel_path))\n",
    "it = checkpoint_io.load('model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load option depends on whether GPU is used\n",
    "device_load_options = {} if use_cuda else {'map_location': lambda storage, loc: storage}\n",
    " \n",
    "# Put models on gpu if needed\n",
    "with torch.enable_grad():\n",
    "    generator_test = generator_test.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class LarsGenerator(gen.PTNoiseTransformerAdapter):\n",
    "    def __init__(self, ydist, module, tensor_type=torch.cuda.FloatTensor):\n",
    "        f_sample_noise = lambda n: torch.randn(n, 256).float()\n",
    "        in_out_shapes = (256, (3, 256, 256))\n",
    "        super(LarsGenerator, self).__init__(module, f_sample_noise, in_out_shapes, tensor_type)\n",
    "        self.post_process = gen.LinearRangeTransform(from_range=(-1,1), to_range=(0,1))\n",
    "        self.ydist = ydist\n",
    "        \n",
    "        \n",
    "    def forward(self, Z):\n",
    "        # self.generator is the same as self.module\n",
    "        y_sam = self.ydist.sample((Z.shape[0], ))\n",
    "        sam_minus1_plus1 = self.module.forward(Z, y_sam)\n",
    "        # make sure to transform the output to (0,1)\n",
    "#         print(dir(self))\n",
    "        result = self.post_process.forward(sam_minus1_plus1)\n",
    "#         result = sam_minus1_plus1\n",
    "        return result\n",
    "    \n",
    "# Construct a generator\n",
    "nlabels = config['data']['nlabels']  \n",
    "ydist = get_ydist(nlabels, device=device)\n",
    "g = LarsGenerator(ydist, generator_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_sample = 8\n",
    "z = torch.randn(n_sample, 256).float()\n",
    "g_samples = g.forward(z)\n",
    "plot.show_torch_imgs(g_samples.detach().cpu(), nrow=4, normalize=True, figsize=(10, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.describe(g_samples.detach().cpu().numpy().reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Generator output shape:', g_samples[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\arg\\min_z \\|g(z) - y\\|_p^2$ where $y$ is an image of a digit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "# img_fname = '0a179ae9d4cc0144343aedd4a87aa686419dfd19.png'\n",
    "# img_fname = '014fa62f91297b31ba43d0e7b14d8df256da287d.png'\n",
    "img_fname = '05c622a21e04560050cce84192a79765973a60b3.png'\n",
    "img_path = glo.share_path('lsun_imgs', 'bedroom', img_fname)\n",
    "img = imageio.imread(img_path)\n",
    "print(stats.describe(img.reshape(-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img);\n",
    "print('Image shape:', img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to float in range [0,1], and resize to 256 x 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import skimage\n",
    "import kbrgan.imutil as imutil\n",
    "float_img = imutil.numpy_image_to_float(img)\n",
    "# plt.imshow(float_img);\n",
    "\n",
    "# resize\n",
    "resized = skimage.transform.resize(float_img, (256, 256))\n",
    "plt.imshow(resized)\n",
    "print(stats.describe(resized.reshape(-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a Pytorch image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts a PIL Image or numpy.ndarray (H x W x C) in the range [0, 255] to a \n",
    "# torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0].\n",
    "torch_converter = transforms.ToTensor()\n",
    "pt_img = torch_converter(resized).to(device).type(tensor_type)\n",
    "plot.show_torch_imgs(pt_img)\n",
    "print('Pytorch image shape:', pt_img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimization to find an approximate inverse of the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "squared_loss = lambda x, y: torch.sum( (x-y)**2 )\n",
    "# l1_loss = lambda x,y: torch.sum( torch.abs(x-y) )\n",
    "f_loss = squared_loss\n",
    "opts = {\n",
    "    'n_opt_iter': 300,\n",
    "    'lr': 1e-2,\n",
    "}\n",
    "input_img = pt_img.to(device)\n",
    "\n",
    "# initialize z\n",
    "z0 = g.sample_noise(1)\n",
    "z0 = z0.to(device)\n",
    "z0.requires_grad = True\n",
    "\n",
    "with torch.no_grad():\n",
    "    y0 = g(z0)\n",
    "#     plot.show_torch_imgs(y0)\n",
    "\n",
    "losses, Zs = gen.decode_generator(g, z0, input_img, f_loss, **opts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the recorded losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_opt_iter = opts['n_opt_iter']\n",
    "plt.plot(losses, 'b-', label='Loss')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the recorded noise vectors during the optimization (as images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_every = 40\n",
    "Zs_toshow = Zs[0::n_every]\n",
    "n_toshow = len(Zs_toshow)\n",
    "\n",
    "# transform to get images\n",
    "with torch.no_grad():\n",
    "    Z_cat = torch.cat(Zs_toshow, dim=0).to(device)\n",
    "    gen_toshow = g.forward(Z_cat)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Optimized images. Every {} iterations.'.format(n_every))\n",
    "plot.show_torch_imgs(gen_toshow, nrow=4, figsize=(10, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Conditioned image')\n",
    "plot.show_torch_imgs(input_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
